{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.38519938,  0.02641654],\n",
       "       [-1.74830343, -1.4226907 ],\n",
       "       [-2.45431681, -1.46071435],\n",
       "       ...,\n",
       "       [-1.88691344, -1.67526794],\n",
       "       [-0.96714666,  4.62965124],\n",
       "       [-1.78872907,  3.53964501]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造一些数据点\n",
    "centers = [[-5, 0], [0, 1.5]]\n",
    "X, y = make_blobs(n_samples=1000, centers=centers, random_state=40)\n",
    "transformation = [[0.4, 0.2], [-0.4, 1.2]]\n",
    "X = np.dot(X, transformation)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.385199</td>\n",
       "      <td>0.026417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.748303</td>\n",
       "      <td>-1.422691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.454317</td>\n",
       "      <td>-1.460714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.125613</td>\n",
       "      <td>1.839601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.885640</td>\n",
       "      <td>0.015078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0 -2.385199  0.026417\n",
       "1 -1.748303 -1.422691\n",
       "2 -2.454317 -1.460714\n",
       "3 -1.125613  1.839601\n",
       "4 -1.885640  0.015078"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_X = pd.DataFrame(X)\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  1\n",
       "4  0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n",
    "df_y = pd.DataFrame(y)\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.385199</td>\n",
       "      <td>0.026417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.748303</td>\n",
       "      <td>-1.422691</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.454317</td>\n",
       "      <td>-1.460714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.125613</td>\n",
       "      <td>1.839601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.885640</td>\n",
       "      <td>0.015078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2  y\n",
       "0 -2.385199  0.026417  0\n",
       "1 -1.748303 -1.422691  0\n",
       "2 -2.454317 -1.460714  0\n",
       "3 -1.125613  1.839601  1\n",
       "4 -1.885640  0.015078  0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([df_X,df_y],axis=1)\n",
    "df.columns = ['x1','x2','y']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994\n",
      "intercept: [5.26633759]\n",
      "coef [[4.83543236 2.40770116]]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# GBDT算法\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# 随机拆分训练集与测试集\n",
    "# train_x, test_x, train_y, test_y = train_test_split(df.iloc[:, :2], df.iloc[:, 2], test_size = 0.2)\n",
    "x, y = df.iloc[:, :2], df.iloc[:, 2]\n",
    "# 逻辑回归分类算法\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# 训练模型\n",
    "# lr.fit(train_x, train_y)\n",
    "lr.fit(x, y)\n",
    "\n",
    "# 预测\n",
    "# predict_y = lr.predict(test_x)\n",
    "# print(predict_y)\n",
    "\n",
    "# 模型得分\n",
    "score = lr.score(x, y)\n",
    "print(score)\n",
    "# sklearn —— lr的intercept\n",
    "print('intercept:', lr.intercept_)\n",
    "print('coef', lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import  VectorAssembler\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.feature import RFormula\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"LogisticRegressionSummary\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+---+\n",
      "|                 x1|                  x2|  y|\n",
      "+-------------------+--------------------+---+\n",
      "| -2.385199377182053| 0.02641654153650963|  0|\n",
      "| -1.748303425101968| -1.4226907036418683|  0|\n",
      "|-2.4543168092113743| -1.4607143493286543|  0|\n",
      "|-1.1256129399722343|  1.8396010662311215|  1|\n",
      "|-1.8856403930555201|0.015077984693015356|  0|\n",
      "+-------------------+--------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(df)\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+\n",
      "|summary|                 x1|                x2|\n",
      "+-------+-------------------+------------------+\n",
      "|  count|               1000|              1000|\n",
      "|   mean|-1.3192309800110293|0.4906036582218552|\n",
      "| stddev| 0.8709577892170187|1.8635558731525261|\n",
      "|    min|-4.0920421418646775| -4.88341015185696|\n",
      "|    max| 1.2690910070542518| 5.406472714716774|\n",
      "+-------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.describe(['x1','x2']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+---+--------------------+-----+\n",
      "|                 x1|                  x2|  y|            features|label|\n",
      "+-------------------+--------------------+---+--------------------+-----+\n",
      "| -2.385199377182053| 0.02641654153650963|  0|[-2.3851993771820...|  0.0|\n",
      "| -1.748303425101968| -1.4226907036418683|  0|[-1.7483034251019...|  0.0|\n",
      "|-2.4543168092113743| -1.4607143493286543|  0|[-2.4543168092113...|  0.0|\n",
      "|-1.1256129399722343|  1.8396010662311215|  1|[-1.1256129399722...|  1.0|\n",
      "|-1.8856403930555201|0.015077984693015356|  0|[-1.8856403930555...|  0.0|\n",
      "+-------------------+--------------------+---+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 提取特征与目标\n",
    "fomula = RFormula(formula = 'y ~ .')\n",
    "raw_df = fomula.fit(spark_df).transform(spark_df)\n",
    "raw_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分训练集和测试集\n",
    "# train_df, test_df = raw_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# 创建LR分类器\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# 训练\n",
    "# train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = lr.fit(train_df)\n",
    "model = lr.fit(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+---+--------------------+-----+--------------------+--------------------+----------+\n",
      "|                 x1|                  x2|  y|            features|label|       rawPrediction|         probability|prediction|\n",
      "+-------------------+--------------------+---+--------------------+-----+--------------------+--------------------+----------+\n",
      "| -2.385199377182053| 0.02641654153650963|  0|[-2.3851993771820...|  0.0|[12.5191484349171...|[0.99999634404089...|       0.0|\n",
      "| -1.748303425101968| -1.4226907036418683|  0|[-1.7483034251019...|  0.0|[12.4363591611965...|[0.99999602848582...|       0.0|\n",
      "|-2.4543168092113743| -1.4607143493286543|  0|[-2.4543168092113...|  0.0|[19.8131630172131...|[0.99999999751542...|       0.0|\n",
      "|-1.1256129399722343|  1.8396010662311215|  1|[-1.1256129399722...|  1.0|[-8.3739689146985...|[2.30744461788483...|       1.0|\n",
      "|-1.8856403930555201|0.015077984693015356|  0|[-1.8856403930555...|  0.0|[7.46891633132487...|[0.99942977909231...|       0.0|\n",
      "+-------------------+--------------------+---+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 预测test集合\n",
    "# predict_df = model.transform(test_df)\n",
    "predict_df = model.transform(raw_df)\n",
    "predict_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+---+--------------------+-----+--------------------+--------------------+----------+\n",
      "|                 x1|                  x2|  y|            features|label|       rawPrediction|         probability|prediction|\n",
      "+-------------------+--------------------+---+--------------------+-----+--------------------+--------------------+----------+\n",
      "| -2.385199377182053| 0.02641654153650963|  0|[-2.3851993771820...|  0.0|[12.5191484349171...|[0.99999634404089...|       0.0|\n",
      "| -1.748303425101968| -1.4226907036418683|  0|[-1.7483034251019...|  0.0|[12.4363591611965...|[0.99999602848582...|       0.0|\n",
      "|-2.4543168092113743| -1.4607143493286543|  0|[-2.4543168092113...|  0.0|[19.8131630172131...|[0.99999999751542...|       0.0|\n",
      "|-1.1256129399722343|  1.8396010662311215|  1|[-1.1256129399722...|  1.0|[-8.3739689146985...|[2.30744461788483...|       1.0|\n",
      "|-1.8856403930555201|0.015077984693015356|  0|[-1.8856403930555...|  0.0|[7.46891633132487...|[0.99942977909231...|       0.0|\n",
      "+-------------------+--------------------+---+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_df = model.transform(raw_df)\n",
    "predict_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.9999963440408975, 3.655959102346e-06]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.9999960284858289, 3.971514170951432e-06]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.9999999975154221, 2.4845779777244565e-09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.00023074446178848393, 0.9997692555382116]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.9994297790923127, 0.0005702209076873891]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    probability\n",
       "0      [0.9999963440408975, 3.655959102346e-06]\n",
       "1   [0.9999960284858289, 3.971514170951432e-06]\n",
       "2  [0.9999999975154221, 2.4845779777244565e-09]\n",
       "3  [0.00023074446178848393, 0.9997692555382116]\n",
       "4   [0.9994297790923127, 0.0005702209076873891]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.select('probability').toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00023074446178851627"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wxb = -(10.209934496107765*(-1.1256129399722343) + \n",
    " 4.430228817925033*1.8396010662311215 +  \n",
    " 11.71654964268366)\n",
    "big = 2.718281828459 ** wxb\n",
    "big / (1+big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对测试集做predict, 生成(预测分类, 正确分类)\n",
    "def build_predict_target(row):\n",
    "    return (float(row.prediction), float(row.y))\n",
    "\n",
    "predict_and_target_rdd = predict_df.rdd.map(build_predict_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9930239520958084\n"
     ]
    }
   ],
   "source": [
    "# 统计模型效果\n",
    "metrics = BinaryClassificationMetrics(predict_and_target_rdd)\n",
    "print(metrics.areaUnderPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [10.209934496107765,4.430228817925033]\n",
      "Intercept: 11.71654964268366\n"
     ]
    }
   ],
   "source": [
    "# spark的系数与截距\n",
    "print(\"Coefficients: \" + str(model.coefficients))\n",
    "print(\"Intercept: \" + str(model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.209934496107765, 4.430228817925033]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.coefficients)\n",
    "# model.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = pd.DataFrame(lr.coef_, columns=X.columns)\n",
    "weight = pd.concat([weight, pd.DataFrame(lr.intercept_, columns=['intercept'])], axis=1)\n",
    "\n",
    "# 增加id列是为了解决权重后期相乘计算问题\n",
    "weight = pd.concat([weight, pd.DataFrame(np.array([1]), columns=['id'])], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x1', 'x2', 'y', 'features', 'label']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wxb = -(10.209934496107765*(-2.385199377182053) + \n",
    " 4.430228817925033*0.02641654153650963 +  \n",
    " 11.71654964268366)\n",
    "big = 2.718281828459 ** wxb\n",
    "big / (1+big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_list = [-0.7816175677294058,0.5477111013627193,7.6443351623435545,-0.5748801759905937,-0.42027007731042154,0.29231073398711066,4.272040352801078,-0.34739586823420554,0.2145981403766586,-0.40415069197636677,0.12383300125220871,0.34573268366153476,0.06080121567168719,-0.3450963962713452,0.11033544831366296,0.30794444793466413,0.5375354678582245,0.04823501613857324,0.11626184143697531,0.13765776209775113,-0.13334708891100816,-0.011552788830795174,0.38278599210120395,-2.615143604484861,-0.6625679839416263,0.08666411747007477,-0.8133271454491996]\n",
    "Intercept = -3.1160763612649744\n",
    "len(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(\"parameterVerificationLR.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_line = data.loc[1,:][1:-5].values.tolist()\n",
    "len(first_line)\n",
    "molecule =2.718281828459 ** (-(sum([first_line[i] * w_list[i] for i in range(len(first_line))])+Intercept))\n",
    "molecule / (1 + molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "spark=SparkSession.builder.appName('StandScalerExample').getOrCreate()\n",
    "dataFrame=spark.createDataFrame([(0.0,Vectors.dense([1.0,0.1,-8.0]),),\n",
    "                                 (1.0,Vectors.dense([2.0,1.0,-4.0]),),\n",
    "                                 (1.0,Vectors.dense([4.0,10.0,8.0]),)],['label','features'])\n",
    "#按特征列减均值除标准差——标准化\n",
    "scaler=StandardScaler(inputCol='features',outputCol='scaledFeatures',withStd=False,withMean=True)\n",
    "scalerModel=scaler.fit(dataFrame)\n",
    "scaledData=scalerModel.transform(dataFrame)\n",
    "scaledData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledData.select(['label', 'scaledFeatures']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.select('features').show(truncate=False)\n",
    "scaler=StandardScaler(inputCol='features',outputCol='scaledFeatures',withStd=False,withMean=True)\n",
    "scalerModel=scaler.fit(train_df)\n",
    "scaledData=scalerModel.transform(train_df)\n",
    "scaledData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "dataFrame.show()\n",
    "df = dataFrame\n",
    "def to_array(col):\n",
    "    def to_array_(v):\n",
    "        return v.toArray().tolist()\n",
    "    return udf(to_array_, ArrayType(DoubleType()))(col)\n",
    "column = ['a', 'b', 'c']\n",
    "df = df.withColumn(\"xs\", to_array(col(\"features\"))) \\\n",
    "            .select([\"label\"] + [col(\"xs\")[i] for i in range(3)])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.show()\n",
    "s = dataFrame.drop('label')\n",
    "s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "\n",
    "sd = df.withColumn(\"id\", fn.monotonically_increasing_id())\n",
    "sd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.select(['label', 'id']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.show()\n",
    "sd = sd.drop('label', 'xs[0]')\n",
    "sd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "df = output.select(['features', 'label'])\n",
    "def to_array(col):\n",
    "    def to_array_(v):\n",
    "        return v.toArray().tolist()\n",
    "    return udf(to_array_, ArrayType(DoubleType()))(col)\n",
    "df = df.withColumn(\"xs\", to_array(col(\"features\"))) \\\n",
    "            .select([\"label\"] + [col(\"xs\")[i] for i in range(3)])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import MaxAbsScaler\n",
    "\n",
    "def columnProcessing(data,columnLabel,allColumn):\n",
    "    \n",
    "    #删除目标列\n",
    "    allColumn.remove(columnLabel)\n",
    "    \n",
    "    assembler = VectorAssembler(\n",
    "      inputCols=[columnLabel], outputCol=\"features\"\n",
    "    )\n",
    "\n",
    "    data = assembler.transform(data)\n",
    "#     scaler=MaxAbsScaler(inputCol='features',outputCol='scaledFeatures').fit(data)\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",withStd=True, withMean=True).fit(data)\n",
    "    data = scaler.transform(data)\n",
    "\n",
    "    \n",
    "    def to_array(col):\n",
    "        def to_array_(v):\n",
    "            return v.toArray().tolist()\n",
    "        return udf(to_array_, ArrayType(DoubleType()))(col)\n",
    "    data = data \\\n",
    "                .withColumn(columnLabel, to_array(col(\"scaledFeatures\"))) \\\n",
    "                .select(allColumn + [col(columnLabel)[0] for i in range(1)]) \\\n",
    "                .withColumnRenamed('%s[0]'%columnLabel,columnLabel)\n",
    "    #           .select([\"xs[0]\", \"xs[1]\", \"xs[2]\"] + [col(\"label\")[i] for i in range(1)])\n",
    "\n",
    "    return data\n",
    "for i in df.columns:\n",
    "    if i == 'label':\n",
    "        continue\n",
    "    df = columnProcessing(df, i,df.columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommed_index_visit_company_sku_class1_cross_feature(self):\n",
    "        '''\n",
    "        用户与曝光的交叉特征\n",
    "        '''\n",
    "        data = self.spark.sql('''\n",
    "                    select * from search_data.recommed_index_visit_company_sku_class1_cross_feature\n",
    "                ''')\n",
    "        return data\n",
    "        \n",
    "        # 删除包含空行的值\n",
    "        data = data.na.drop()\n",
    "\n",
    "        return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
